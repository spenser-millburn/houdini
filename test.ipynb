{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\"\"\"\n",
    "TextGeneration Class Summary:\n",
    "\n",
    "The TextGeneration class facilitates text generation using the OpenAI GPT-3.5 model. \n",
    "\n",
    "Attributes:\n",
    "- client: An instance of the OpenAI API used for text generation.\n",
    "\n",
    "Methods:\n",
    "- __init__(self): Initializes the TextGeneration class with a specified topic for text generation.\n",
    "- generate_json(self, user_prompt, system_prompt=None): Generates a JSON response based on user prompts and an optional system prompt\n",
    "- generate_text(self, user_prompt, system_prompt=None): Generates a text-based response based on user prompts and an optional system prompt\n",
    "\n",
    "Usage:\n",
    "1. Instantiate TextGeneration \n",
    "2. Utilize the generate_json method to generate JSON responses based on user and system prompts.\n",
    "3. Utilize the generate_text method to generate text-based responses based on user and system prompts.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class GPTWrapper:\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI()\n",
    "\n",
    "    def generate_html(self, user_prompt, system_prompt=None, topic=\"everything\"):\n",
    "        if system_prompt is None:\n",
    "            system_prompt = f\"You are a helpful assistant that knows a lot about {topic} and only responds with HTML with only the HTML code. Nicely format with different header sizes and tables when necessary\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"{user_prompt}\"},\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def generate_json(self, user_prompt, system_prompt=None, topic=\"everything\"):\n",
    "        if system_prompt is None:\n",
    "            system_prompt = f\"You are a helpful assistant that knows a lot about {topic} and only responds with JSON\"\n",
    "\n",
    "        return self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"{user_prompt}\"},\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def generate_text(self, user_prompt, system_prompt=None, topic=\"everything\"):\n",
    "        if system_prompt is None:\n",
    "            system_prompt = f\"You are a helpful assistant that knows a lot about {topic}\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"{user_prompt}\"},\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def generate_dockerfile(self, user_prompt, system_prompt=None, topic=\"everything\"):\n",
    "        if system_prompt is None:\n",
    "            system_prompt = f\"You are a helpful assistant that knows how to make a Dockerfile that will achieve the following output: {topic}. I would like you to respond with only the text for a Dockerfile nothing else. No extra code or files allowed, but you can write inline code in the Dockerfile. Ensure that the dockerfile is runnable\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"{user_prompt}\"},\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip(\"`\").strip(\"Dockerfile\").strip('dockerfile')\n",
    "\n",
    "    def refine_dockerfile(self, user_prompt, dockerfile_string, build_logs, run_logs ,errors , topic=\"everything\"):\n",
    "\n",
    "        system_prompt = f\"You are a helpful assistant that knows how to improve this existing dockerfile ({dockerfile_string}) so that it will achieve the following output: {topic}. I would like you to respond with only the text for the improved Dockerfile nothing else. Ensure that the dockerfile is runnable. Here are the build logs from when I built the image: {build_logs} and the runtime logs: {run_logs}. If any, here are the errors that occurred: {errors}\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"{user_prompt}\"},\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip(\"`\").strip(\"Dockerfile\").strip('dockerfile')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import uuid\n",
    "import os\n",
    "from docker import DockerClient, errors\n",
    "\n",
    "class DockerRunner:\n",
    "    def __init__(self):\n",
    "        self.docker_client = DockerClient(base_url='unix://var/run/docker.sock')\n",
    "\n",
    "    def run_dockerfile(self, dockerfile_path, run_duration=5):\n",
    "        # Generate a random directory to store the Dockerfile\n",
    "        dir_path = f\"temp/{str(uuid.uuid4())}\"\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        temp_dockerfile_path = os.path.join(dir_path, \"Dockerfile\")\n",
    "        \n",
    "        # Prepare the response dictionary\n",
    "        response = {\"dockerfile\": dockerfile_path}\n",
    "        with open(dockerfile_path, 'r') as file: data = file.read() \n",
    "        response[\"dockerfile_content\"] = data\n",
    "        response[\"task\"] = task\n",
    "        \n",
    "        try:\n",
    "            # Copy Dockerfile to the temporary directory\n",
    "            shutil.copy(dockerfile_path, temp_dockerfile_path)\n",
    "            \n",
    "            # Build the Docker image\n",
    "            image, build_logs = self.docker_client.images.build(path=dir_path, rm=True, forcerm=True)\n",
    "            response[\"build_logs\"] = [log.get('stream', '') for log in build_logs if 'stream' in log]\n",
    "            \n",
    "            # Run the container\n",
    "            container = self.docker_client.containers.run(image.id, detach=True)\n",
    "            \n",
    "            # Wait for the specified run duration\n",
    "            container.wait(timeout=run_duration)\n",
    "            \n",
    "            # Capture runtime logs\n",
    "            logs = container.logs(timestamps=True).decode('utf-8')\n",
    "            response[\"run_logs\"] = logs\n",
    "            \n",
    "            # Stop and remove the container\n",
    "            container.stop()\n",
    "            container.remove()\n",
    "            \n",
    "        except (errors.DockerException, errors.APIError) as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            response[\"error\"] = str(e)\n",
    "        \n",
    "        finally:\n",
    "            # Cleanup: remove the directory after building\n",
    "            shutil.rmtree(dir_path)\n",
    "        \n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pp\n",
    "llm = GPTWrapper()\n",
    "\n",
    "def build_initial ( task):\n",
    "  dockerfile_lines = [llm.generate_dockerfile(task)]\n",
    "  df  = [open(f'./Dockerfile', 'w').write(element) for i, element in enumerate(dockerfile_lines)]\n",
    "  pp(df)\n",
    "\n",
    "def run_dockerfile():\n",
    "  docker_runner = DockerRunner()\n",
    "  result = docker_runner.run_dockerfile(\"./Dockerfile\")\n",
    "  from pprint import pp\n",
    "  return result\n",
    "\n",
    "def iterate(new_result, user_feedback, task):\n",
    "  refined_dockerfile_lines= \"\"\n",
    "  refined_dockerfile_lines = llm.refine_dockerfile(user_feedback, dockerfile_string=new_result.get('dockerfile_content'),build_logs=new_result.get('build_logs not available', None),run_logs=new_result.get('run_logs', \"run logs not available\") , errors=new_result.get(\"error\", \"no errors\"), topic=task)\n",
    "  open(f'./Dockerfile', 'w').write(refined_dockerfile_lines)\n",
    "  return run_dockerfile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86]\n",
      "{'dockerfile': './Dockerfile',\n",
      " 'dockerfile_content': '\\n'\n",
      "                       'FROM python:latest\\n'\n",
      "                       '\\n'\n",
      "                       \"RUN python -c 'import random; \"\n",
      "                       \"print(random.randint(100, 10000))'\\n\",\n",
      " 'task': 'use python to make a random number from 100 to 10000',\n",
      " 'build_logs': ['Step 1/2 : FROM python:latest',\n",
      "                '\\n',\n",
      "                ' ---> 6cbe1053f244\\n',\n",
      "                \"Step 2/2 : RUN python -c 'import random; \"\n",
      "                \"print(random.randint(100, 10000))'\",\n",
      "                '\\n',\n",
      "                ' ---> Running in a45ff2ea0d28\\n',\n",
      "                '3001\\n',\n",
      "                ' ---> Removed intermediate container a45ff2ea0d28\\n',\n",
      "                ' ---> 78d434976349\\n',\n",
      "                'Successfully built 78d434976349\\n'],\n",
      " 'run_logs': ''}\n"
     ]
    }
   ],
   "source": [
    "task = \"use python to make a random number from 100 to 10000\"\n",
    "build_initial(task)\n",
    "result = run_dockerfile()\n",
    "pp(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dockerfile': './Dockerfile',\n",
       "  'dockerfile_content': '\\nFROM python:latest\\n\\nCMD [\"python\", \"-c\", \"import random; print(random.randint(100, 10000))\"]\\n',\n",
       "  'task': 'use python to make a random number from 100 to 10000',\n",
       "  'build_logs': ['Step 1/2 : FROM python:latest',\n",
       "   '\\n',\n",
       "   ' ---> 6cbe1053f244\\n',\n",
       "   'Step 2/2 : CMD [\"python\", \"-c\", \"import random; print(random.randint(100, 10000))\"]',\n",
       "   '\\n',\n",
       "   ' ---> Using cache\\n',\n",
       "   ' ---> ed26d8f5daf8\\n',\n",
       "   'Successfully built ed26d8f5daf8\\n'],\n",
       "  'run_logs': '2024-04-02T02:40:32.970981331Z 183\\n'},\n",
       " {'dockerfile': './Dockerfile',\n",
       "  'dockerfile_content': '\\nFROM python:latest\\n\\nCMD [\"python\", \"-c\", \"import random; print(random.randint(100, 10000))\"]\\n',\n",
       "  'task': 'use python to make a random number from 100 to 10000',\n",
       "  'build_logs': ['Step 1/2 : FROM python:latest',\n",
       "   '\\n',\n",
       "   ' ---> 6cbe1053f244\\n',\n",
       "   'Step 2/2 : CMD [\"python\", \"-c\", \"import random; print(random.randint(100, 10000))\"]',\n",
       "   '\\n',\n",
       "   ' ---> Using cache\\n',\n",
       "   ' ---> ed26d8f5daf8\\n',\n",
       "   'Successfully built ed26d8f5daf8\\n'],\n",
       "  'run_logs': '2024-04-02T02:40:34.633093560Z 4219\\n'},\n",
       " {'dockerfile': './Dockerfile',\n",
       "  'dockerfile_content': \"\\nFROM python:latest\\n\\nRUN python -c 'import random; print(random.randint(100, 10000))'\\n\",\n",
       "  'task': 'use python to make a random number from 100 to 10000',\n",
       "  'build_logs': ['Step 1/2 : FROM python:latest',\n",
       "   '\\n',\n",
       "   ' ---> 6cbe1053f244\\n',\n",
       "   \"Step 2/2 : RUN python -c 'import random; print(random.randint(100, 10000))'\",\n",
       "   '\\n',\n",
       "   ' ---> Using cache\\n',\n",
       "   ' ---> 78d434976349\\n',\n",
       "   'Successfully built 78d434976349\\n'],\n",
       "  'run_logs': ''},\n",
       " {'dockerfile': './Dockerfile',\n",
       "  'dockerfile_content': \"FROM python:latest\\n\\nRUN python -c 'import random; print(random.randint(100, 10000))'\",\n",
       "  'task': 'use python to make a random number from 100 to 10000',\n",
       "  'build_logs': ['Step 1/2 : FROM python:latest',\n",
       "   '\\n',\n",
       "   ' ---> 6cbe1053f244\\n',\n",
       "   \"Step 2/2 : RUN python -c 'import random; print(random.randint(100, 10000))'\",\n",
       "   '\\n',\n",
       "   ' ---> Using cache\\n',\n",
       "   ' ---> 78d434976349\\n',\n",
       "   'Successfully built 78d434976349\\n'],\n",
       "  'run_logs': ''},\n",
       " {'dockerfile': './Dockerfile',\n",
       "  'dockerfile_content': \"\\nFROM python:latest\\n\\nRUN python -c 'import random; print(random.randint(100, 10000))' \\n\",\n",
       "  'task': 'use python to make a random number from 100 to 10000',\n",
       "  'build_logs': ['Step 1/2 : FROM python:latest',\n",
       "   '\\n',\n",
       "   ' ---> 6cbe1053f244\\n',\n",
       "   \"Step 2/2 : RUN python -c 'import random; print(random.randint(100, 10000))'\",\n",
       "   '\\n',\n",
       "   ' ---> Using cache\\n',\n",
       "   ' ---> 78d434976349\\n',\n",
       "   'Successfully built 78d434976349\\n'],\n",
       "  'run_logs': ''}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO make llm provide feedback for GAN like iteration\n",
    "[iterate(new_result=result,user_feedback=\"\",task= task) for i in range(5)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dockerfile': './Dockerfile',\n",
       " 'dockerfile_content': \"FROM python:latest\\n\\nCMD python -c 'import random; print(random.randint(100, 10000))'\",\n",
       " 'task': 'use python to make a random number from 100 to 10000',\n",
       " 'build_logs': ['Step 1/2 : FROM python:latest',\n",
       "  '\\n',\n",
       "  ' ---> 6cbe1053f244\\n',\n",
       "  \"Step 2/2 : CMD python -c 'import random; print(random.randint(100, 10000))'\",\n",
       "  '\\n',\n",
       "  ' ---> Running in 1397eb71a048\\n',\n",
       "  ' ---> Removed intermediate container 1397eb71a048\\n',\n",
       "  ' ---> 5bc94424fdb9\\n',\n",
       "  'Successfully built 5bc94424fdb9\\n'],\n",
       " 'run_logs': '2024-04-02T02:39:57.886425133Z 6127\\n'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "iterate(new_result=result,user_feedback=\"\",task= task) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
